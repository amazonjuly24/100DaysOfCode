{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser as fp\n",
    "import numpy as np\n",
    "import json\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 10\n",
    "articles_array = []\n",
    "\n",
    "data = {}\n",
    "data['newspapers'] = {}\n",
    "\n",
    "# Loads the JSON files with news sites\n",
    "with open('NewsPapers.json') as data_file:\n",
    "    companies = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading articles from  theguardian\n",
      "1 articles downloaded from theguardian , url:  https://www.theguardian.com/world/live/2018/jul/06/thailand-cave-rescue-looming-rain-clouds-could-force-quick-rescue-decision-live\n",
      "2 articles downloaded from theguardian , url:  https://www.theguardian.com/politics/2018/jul/06/michel-barnier-eu-willing-to-compromise-if-uk-softens-brexit-red-lines\n",
      "3 articles downloaded from theguardian , url:  https://www.theguardian.com/football/live/2018/jul/06/world-cup-2018-quarter-final-brazil-v-belgium-live\n",
      "4 articles downloaded from theguardian , url:  https://www.theguardian.com/uk-news/2018/jul/06/sinkhole-traps-truck-as-uk-heatwave-takes-toll-on-roads\n",
      "5 articles downloaded from theguardian , url:  https://www.theguardian.com/us-news/2018/jul/06/donald-trump-to-avoid-london-during-uk-visit\n",
      "6 articles downloaded from theguardian , url:  https://www.theguardian.com/uk-news/2018/jul/06/second-man-arrested-over-lancashire-moorland-fire\n",
      "7 articles downloaded from theguardian , url:  https://www.theguardian.com/uk-news/2018/jul/06/teenager-in-court-charged-with-and-of-girl-on-bute-alesha-macphail\n",
      "8 articles downloaded from theguardian , url:  https://www.theguardian.com/science/2018/jul/06/top-oncologist-to-study-effect-of-diet-on-cancer-drugs\n",
      "9 articles downloaded from theguardian , url:  https://www.theguardian.com/music/2018/jul/06/chris-brown-arrested-florida-felony-battery\n",
      "10 articles downloaded from theguardian , url:  https://www.theguardian.com/books/2018/jul/06/jk-rowling-attacked-for-saying-scottish-nationalism-contains-traces-of-bigotry\n",
      "Downloading articles from  washingtonpost\n",
      "Building site for  nbcnews\n",
      "1 articles downloaded from nbcnews  using newspaper, url:  https://www.nbcnews.com/dateline/video/into-the-wild-part-6-983861827883\n",
      "2 articles downloaded from nbcnews  using newspaper, url:  https://www.nbcnews.com/news/world/divorce-rise-iraq-wives-cut-ties-isis-militants-n888541\n",
      "3 articles downloaded from nbcnews  using newspaper, url:  http://www.nbcnews.com/health/health-news/smoking-hits-all-time-low-u-s-n884621\n",
      "4 articles downloaded from nbcnews  using newspaper, url:  https://www.nbcnews.com/feature/nbc-out\n",
      "5 articles downloaded from nbcnews  using newspaper, url:  https://www.nbcnews.com/feature/nbc-out/scarlett-johansson-faces-firestorm-amid-news-she-will-play-transgender-n889036\n",
      "6 articles downloaded from nbcnews  using newspaper, url:  http://www.nbcnews.com/leftfield/video/the-maybe-pretend-prince-and-princess-who-want-to-make-serbia-great-again-1230420547636\n",
      "7 articles downloaded from nbcnews  using newspaper, url:  http://www.nbcnews.com/health/health-news/fewer-teens-having-sex-doing-drugs-more-are-depressed-n883276\n",
      "8 articles downloaded from nbcnews  using newspaper, url:  http://www.nbcnews.com/news/us-news/cardinal-theodore-mccarrick-ex-archbishop-washington-removed-ministry-after-sex-n885006\n",
      "9 articles downloaded from nbcnews  using newspaper, url:  https://www.nbcnews.com/dateline/video/as-night-fell-part-4-976176195523\n",
      "10 articles downloaded from nbcnews  using newspaper, url:  https://www.msnbc.com/velshi-ruhle/watch/for-facts-sake-gun-laws-work-1175351875768\n",
      "Building site for  infowars\n",
      "1 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/video-trump-slams-dishonest-fake-media-for-using-anonymous-sources-to-smear-him/\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/paris-is-a-mess-up-to-400000-illegal-immigrants-live-in-just-one-suburb/#disqus_thread on URL https://www.infowars.com/ https:/www.infowars.com/paris-is-a-mess-up-to-400000-illegal-immigrants-live-in-just-one-suburb/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/new-finnish-party-defying-globalism-migration-emerges/#disqus_thread on URL https://www.infowars.com/ https:/www.infowars.com/new-finnish-party-defying-globalism-migration-emerges/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "2 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/dershowitz-anti-trump-woman-threatened-to-stab-me-in-the-heart/#disqus_thread\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/epa-director-scott-pruitt-resigns-cites-unrelenting-personal-attacks/#disqus_thread on URL https://www.infowars.com/ https:/www.infowars.com/epa-director-scott-pruitt-resigns-cites-unrelenting-personal-attacks/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/nunes-refers-sidney-blumenthal-others-tied-to-trump-dossier-for-testimony/#disqus_thread on URL https://infowars.com/ https:/www.infowars.com/nunes-refers-sidney-blumenthal-others-tied-to-trump-dossier-for-testimony/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "3 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/us-adds-213000-jobs-in-june-better-than-expected/#disqus_thread\n",
      "4 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/poll-immigration-top-issue-for-voters-ahead-of-midterms/\n",
      "5 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/trump-to-opec-reduce-pricing-now/\n",
      "6 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/watch-live-let-the-trade-wars-begin-china-hits-back-with-tariffs/#disqus_thread\n",
      "7 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/korean-media-pompeo-to-give-kim-jong-un-rocket-man-cd-from-trump/#disqus_thread\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/breaking-democrats-officially-call-for-civil-war-and-violence-against-patriots/#disqus_thread on URL https://www.infowars.com/ https:/www.infowars.com/breaking-democrats-officially-call-for-civil-war-and-violence-against-patriots/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "8 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/flashback-leftists-protest-ice-agents-busting-child-sex-ring/\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/video-trump-slams-dishonest-fake-media-for-using-anonymous-sources-to-smear-him/#disqus_thread on URL https://infowars.com/ https:/www.infowars.com/video-trump-slams-dishonest-fake-media-for-using-anonymous-sources-to-smear-him/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/breaking-chinas-military-says-they-are-already-at-war-with-us/#disqus_thread on URL https://www.infowars.com/ https:/www.infowars.com/breaking-chinas-military-says-they-are-already-at-war-with-us/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/italian-newspaper-claims-global-elite-working-to-transform-europe-through-mass-migration/#disqus_thread on URL https://www.infowars.com/ https:/www.infowars.com/italian-newspaper-claims-global-elite-working-to-transform-europe-through-mass-migration/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/roger-stone-kavanaugh-is-deep-states-pick-for-supreme-court/#disqus_thread on URL https://infowars.com/ https:/www.infowars.com/roger-stone-kavanaugh-is-deep-states-pick-for-supreme-court/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/california-lyin-health-choice-vax-mandates/#disqus_thread on URL https://www.infowars.com/ https:/www.infowars.com/california-lyin-health-choice-vax-mandates/#disqus_thread\n",
      "\n",
      "continuing...\n",
      "9 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/watch-live-let-the-trade-wars-begin-china-hits-back-with-tariffs/\n",
      "Article `download()` failed with 404 Client Error: Not Found for url: https://www.infowars.com/%20https:/www.infowars.com/trump-mocks-very-low-iq-maxine-waters/#disqus_thread on URL https://infowars.com/ https:/www.infowars.com/trump-mocks-very-low-iq-maxine-waters/#disqus_thread\n",
      "\n",
      "continuing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 articles downloaded from infowars  using newspaper, url:  https://www.infowars.com/italian-newspaper-claims-global-elite-working-to-transform-europe-through-mass-migration/\n",
      "Downloading articles from  bbc\n",
      "1 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/world-asia-44747049\n",
      "2 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/uk-44741671\n",
      "3 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/uk-scotland-glasgow-west-44738881\n",
      "4 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/uk-44733873\n",
      "5 articles downloaded from bbc , url:  https://www.bbc.co.uk/sport/tennis/44740071\n",
      "6 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/uk-politics-44728807\n",
      "7 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/world-middle-east-44746147\n",
      "8 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/business-44742714\n",
      "9 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/entertainment-arts-44736569\n",
      "10 articles downloaded from bbc , url:  https://www.bbc.co.uk/news/uk-england-44739472\n",
      "Building site for  breitbart\n",
      "1 articles downloaded from breitbart  using newspaper, url:  https://www.breitbart.com/sports/2018/07/02/lapd-has-no-additional-info-six-months-after-alleged-racist-graffiti-at-lebron-james-home/#disqus_thread\n",
      "2 articles downloaded from breitbart  using newspaper, url:  https://www.breitbart.com/big-government/2018/07/05/taxpayers-fund-study-linking-trump-support-opioid-abuse/\n",
      "3 articles downloaded from breitbart  using newspaper, url:  https://www.breitbart.com/video/2018/07/06/broussard-most-woke-thing-black-man-can-do-is-getting-married-raising-strong-intelligent-black-kids/#disqus_thread\n",
      "4 articles downloaded from breitbart  using newspaper, url:  https://www.breitbart.com/big-hollywood/2018/07/03/transgender-model-to-compete-in-miss-universe-pageant/#disqus_thread\n",
      "5 articles downloaded from breitbart  using newspaper, url:  http://www.breitbart.com/video/2018/06/29/michael-moore-ill-join-a-million-other-people-surrounding-capitol-to-delay-vote-on-scotus-pick/\n",
      "6 articles downloaded from breitbart  using newspaper, url:  https://www.breitbart.com/news/rooney-says-he-needed-mls-move-as-new-challenge-looms-4/\n",
      "7 articles downloaded from breitbart  using newspaper, url:  http://www.breitbart.com/london/2018/07/05/amesbury-major-incident-is-second-novichok-poisoning-in-four-months/#disqus_thread\n",
      "8 articles downloaded from breitbart  using newspaper, url:  http://www.breitbart.com/big-government/2018/07/06/exclusive-foreign-minister-no-one-could-say-hungary-first-before-trumps-rise/\n",
      "9 articles downloaded from breitbart  using newspaper, url:  http://www.breitbart.com/sports/2018/07/06/ronda-rousey-becomes-first-female-ufc-hall-of-fame-inductee/\n",
      "10 articles downloaded from breitbart  using newspaper, url:  https://www.breitbart.com/news/china-counterpunches-against-us-in-growing-trade-war/\n",
      "Building site for  cnn\n",
      "1 articles downloaded from cnn  using newspaper, url:  http://edition.cnn.com/2018/03/23/health/intermittent-fasting-food-drayer/index.html\n",
      "2 articles downloaded from cnn  using newspaper, url:  http://wlos.com/news/local/former-sunday-school-teacher-charged-with-sexually-assaulted-children-for-years\n",
      "3 articles downloaded from cnn  using newspaper, url:  http://edition.cnn.com/2018/07/04/entertainment/scarlett-johansson-transgender-role-trnd/index.html\n",
      "4 articles downloaded from cnn  using newspaper, url:  http://edition.cnn.com/2018/07/06/entertainment/ariana-grande-pete-davidson-manchester/index.html\n",
      "Article `download()` failed with 403 Client Error: Forbidden for url: http://edition.cnn.com/videos/cnnmoney/2018/07/05/smartphone-maker-xiaomi-trade-war-us-china-cnnmoney-orig.cnnmoney on URL http://edition.cnn.com/videos/cnnmoney/2018/07/05/smartphone-maker-xiaomi-trade-war-us-china-cnnmoney-orig.cnnmoney\n",
      "\n",
      "continuing...\n",
      "5 articles downloaded from cnn  using newspaper, url:  http://edition.cnn.com/style/article/venice-biennale-2018-architecture-highlights/index.html\n",
      "6 articles downloaded from cnn  using newspaper, url:  http://edition.cnn.com/2018/07/06/politics/separated-parents-children-border-lawsuit/index.html\n",
      "7 articles downloaded from cnn  using newspaper, url:  http://edition.cnn.com/style/article/pierre-berge-yves-saint-laurent-sothebys-auction/index.html\n",
      "8 articles downloaded from cnn  using newspaper, url:  https://www.cnn.com/2018/02/28/cnn-underscored/zoodles-pasta-alternative-shop/index.html?iid=underscoredhealthhpplacement\n",
      "9 articles downloaded from cnn  using newspaper, url:  http://money.cnn.com/2018/07/06/technology/adidas-speedfactory/index.html\n",
      "10 articles downloaded from cnn  using newspaper, url:  http://edition.cnn.com/2017/03/04/vr/how-to-watch-vr\n",
      "Building site for  foxnews\n",
      "1 articles downloaded from foxnews  using newspaper, url:  http://www.foxnews.com/us/2018/07/05/rest-whiskey-storage-warehouse-collapses-in-kentucky.html\n",
      "2 articles downloaded from foxnews  using newspaper, url:  http://insider.foxnews.com/2018/05/03/ainsley-earhardt-5-things-you-didnt-know-facts-photos-family\n",
      "Article `download()` failed with 403 Client Error: Forbidden for url: http://video.foxnews.com/v/5806025413001/?playlist_id=5670932084001 on URL http://video.foxnews.com/v/5806025413001/?playlist_id=5670932084001\n",
      "\n",
      "continuing...\n",
      "3 articles downloaded from foxnews  using newspaper, url:  http://www.foxnews.com/politics/2018/07/06/amy-coney-barrett-criticized-for-ties-to-people-praise-look-at-group.html\n",
      "4 articles downloaded from foxnews  using newspaper, url:  http://www.foxnews.com/entertainment/2018/07/05/big-bang-star-kaley-couco-undergoes-shoulder-surgery-days-after-marrying-karl-cook.html\n",
      "5 articles downloaded from foxnews  using newspaper, url:  http://www.foxnews.com/entertainment/2018/07/06/msnbc-dusts-off-1990s-comedian-sinbad-to-slam-post-dementia-president-trump.html\n",
      "6 articles downloaded from foxnews  using newspaper, url:  http://www.foxnews.com/us/2018/06/26/indiana-teen-killed-by-basketball-backboard-in-freak-accident.html\n",
      "7 articles downloaded from foxnews  using newspaper, url:  http://www.foxbusiness.com/markets/businesses-hit-pause-on-spending-amid-trade-uncertainty-fed-minutes\n",
      "8 articles downloaded from foxnews  using newspaper, url:  http://www.foxnews.com/lifestyle/2018/07/06/wisconsin-newlyweds-nearly-struck-with-falling-tree-branch.html\n",
      "9 articles downloaded from foxnews  using newspaper, url:  https://radio.foxnews.com/2018/06/13/ill-tell-you-what-well-see-what-happens/\n",
      "10 articles downloaded from foxnews  using newspaper, url:  http://insider.foxnews.com/2018/06/03/judge-jeanine-pirro-trey-gowdy-statement-trump-spy-claims-ridiculous\n",
      "Building site for  theonion\n",
      "1 articles downloaded from theonion  using newspaper, url:  https://politics.theonion.com/stephen-miller-furious-at-propublica-for-only-releasing-1826958853\n",
      "2 articles downloaded from theonion  using newspaper, url:  https://local.theonion.com/coworkers-all-saying-names-of-countries-must-mean-world-1826799507\n",
      "3 articles downloaded from theonion  using newspaper, url:  https://local.theonion.com/couple-fucking-at-next-table-obviously-on-third-date-1826735326\n",
      "4 articles downloaded from theonion  using newspaper, url:  https://local.theonion.com/asshole-taking-up-two-plots-1827104786\n",
      "5 articles downloaded from theonion  using newspaper, url:  https://sports.theonion.com/lionel-messi-pissed-after-forgetting-to-wear-fitbit-dur-1826929880\n",
      "6 articles downloaded from theonion  using newspaper, url:  https://sports.theonion.com/red-sox-team-doctor-unclear-whether-he-supposed-to-join-1826270750\n",
      "7 articles downloaded from theonion  using newspaper, url:  https://local.theonion.com/man-offended-by-rude-female-coworker-continuing-to-spea-1827204473\n",
      "8 articles downloaded from theonion  using newspaper, url:  https://www.clickhole.com/more-bad-news-for-democrats-ruth-bader-ginsburg-has-an-1827208652\n",
      "9 articles downloaded from theonion  using newspaper, url:  https://sports.theonion.com/coworker-following-world-cup-goes-all-in-on-tenuous-fam-1826876014\n",
      "10 articles downloaded from theonion  using newspaper, url:  https://sports.theonion.com/yankees-fans-pack-stadium-for-asshole-heritage-night-1826328296\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "# Iterate through each news company\n",
    "for company, value in companies.items():\n",
    "    # If a RSS link is provided in the JSON file, this will be the first choice.\n",
    "    # Reason for this is that, RSS feeds often give more consistent and correct data. RSS (Rich Site Summary; originally RDF Site Summary; often called Really Simple Syndication) is a type of\n",
    "    # web feed which allows users to access updates to online content in a standardized, computer-readable format\n",
    "    # If you do not want to scrape from the RSS-feed, just leave the RSS attr empty in the JSON file.\n",
    "    if 'rss' in value:\n",
    "        d = fp.parse(value['rss'])\n",
    "        print(\"Downloading articles from \", company)\n",
    "        newsPaper = {\n",
    "            \"rss\": value['rss'],\n",
    "            \"link\": value['link'],\n",
    "            \"articles\": []\n",
    "        }\n",
    "        for entry in d.entries:\n",
    "            # Check if publish date is provided, if no the article is skipped.\n",
    "            # This is done to keep consistency in the data and to keep the script from crashing.\n",
    "            if hasattr(entry, 'published'):\n",
    "                if count > LIMIT:\n",
    "                    break\n",
    "                article = {}\n",
    "                article['link'] = entry.link\n",
    "                date = entry.published_parsed\n",
    "                article['published'] = datetime.fromtimestamp(mktime(date)).isoformat()\n",
    "                try:\n",
    "                    content = Article(entry.link)\n",
    "                    content.download()\n",
    "                    content.parse()\n",
    "                except Exception as e:\n",
    "                    # If the download for some reason fails (ex. 404) the script will continue downloading\n",
    "                    # the next article.\n",
    "                    print(e)\n",
    "                    print(\"continuing...\")\n",
    "                    continue\n",
    "                article['title'] = content.title\n",
    "                article['text'] = content.text\n",
    "                article['authors'] = content.authors\n",
    "                article['top_image'] =  content.top_image\n",
    "                article['movies'] = content.movies\n",
    "                newsPaper['articles'].append(article)\n",
    "                articles_array.append(article)\n",
    "                print(count, \"articles downloaded from\", company, \", url: \", entry.link)\n",
    "                count = count + 1\n",
    "    else:\n",
    "        # This is the fallback method if a RSS-feed link is not provided.\n",
    "        # It uses the python newspaper library to extract articles\n",
    "        print(\"Building site for \", company)\n",
    "        paper = newspaper.build(value['link'], memoize_articles=False)\n",
    "        newsPaper = {\n",
    "            \"link\": value['link'],\n",
    "            \"articles\": []\n",
    "        }\n",
    "        noneTypeCount = 0\n",
    "        for content in paper.articles:\n",
    "            if count > LIMIT:\n",
    "                break\n",
    "            try:\n",
    "                content.download()\n",
    "                content.parse()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"continuing...\")\n",
    "                continue\n",
    "            # Again, for consistency, if there is no found publish date the article will be skipped.\n",
    "            # After 10 downloaded articles from the same newspaper without publish date, the company will be skipped.\n",
    "\n",
    "            article = {}\n",
    "            article['title'] = content.title\n",
    "            article['authors'] = content.authors\n",
    "            article['text'] = content.text\n",
    "            article['top_image'] =  content.top_image\n",
    "            article['movies'] = content.movies\n",
    "            article['link'] = content.url\n",
    "            article['published'] = content.publish_date\n",
    "            newsPaper['articles'].append(article)\n",
    "            articles_array.append(article)\n",
    "            print(count, \"articles downloaded from\", company, \" using newspaper, url: \", content.url)\n",
    "            count = count + 1\n",
    "            #noneTypeCount = 0\n",
    "    count = 1\n",
    "    data['newspapers'][company] = newsPaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = csv.writer(open('Scraped_data_news_output.csv', 'w', encoding='utf-8'))\n",
    "    f.writerow(['Title', 'Authors','Text','Image','Videos','Link','Published_Date'])\n",
    "    #print(article)\n",
    "    for artist_name in articles_array:\n",
    "        title = artist_name['title']\n",
    "        authors=artist_name['authors']\n",
    "        text=artist_name['text']\n",
    "        image=artist_name['top_image']\n",
    "        video=artist_name['movies']\n",
    "        link=artist_name['link']\n",
    "        publish_date=artist_name['published']\n",
    "        # Add each artist’s name and associated link to a row\n",
    "        f.writerow([title, authors, text, image, video, link, publish_date])\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
